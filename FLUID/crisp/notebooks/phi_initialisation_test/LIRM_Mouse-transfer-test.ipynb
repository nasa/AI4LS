{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a025e092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/crisp'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "while os.getcwd() != '/home/jupyter/crisp':\n",
    "    os.chdir(\"..\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5582e85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.MouseInitialisedLinearInvariantRiskMinimization import *\n",
    "from models.LinearInvariantRiskMinimization import LinearInvariantRiskMinimization \n",
    "from dataio.DataFrameDataset import *\n",
    "from dataio.datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c64ae631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthetic.facebook_synthetic_data_generator import generator_example\n",
    "\n",
    "dim_inv = 2\n",
    "dim_spu = 2\n",
    "n_exp_train = 6 #int(2e2)\n",
    "n_exp_test = 6\n",
    "n_env = 3\n",
    "save_dir = 'data/synthetic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9541320",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"name\": \"Example Experiment for AH casual ensemble\",\n",
    "    \"short_name\": \"ah_experiment_notebook\",\n",
    "    \"bucket_project\": \"fdl-us-astronaut-health\",\n",
    "    \"bucket_name\": \"ah_21_data\",\n",
    "    \"bucket_path\": \"gs://ah_21_data\",\n",
    "    \"verbose\": 1,\n",
    "    \"test_val_split\": [0.1, 0.1],\n",
    "    \"per_variant_experiment\": False,\n",
    "    \"data_options\": {\n",
    "        #'dataset_fp': '../data/test_multiclass.pkl',\n",
    "        'dataset_fp' : None,\n",
    "        'output_data_regime' : [\"real-valued\", \"binary\", \"binary\", \"real-valued\", \"multi-class\"],\n",
    "        'subject_keys': 'Subj_ID',\n",
    "        'targets': ['Target'],\n",
    " #        'predictors': ['All'],\n",
    "        'predictors': None,\n",
    "        'environments': ['env_split'],\n",
    "        'exclude': ['Subj_ID'],\n",
    "        'synthetic_train_test_split' : True,\n",
    "    },\n",
    "    \"feature_selection_options\": {\n",
    "        \"max_features\": 20,\n",
    "        \"verbose\": 0,\n",
    "        \"seed\": 12\n",
    "    },\n",
    "    \"ensemble_options\": {\n",
    "        \"models\": [\"ERM\", \"RF\", \"ICP\", \"IRM\", \"DCF\", \"ITE\", \"LIRM\", \"NLICP\"]\n",
    "    },\n",
    "    \"use_cloud\":False,\n",
    "    \"results_directory\": \"results/\"\n",
    "}\n",
    "data_config = config['data_options']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e0e87f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIRM_options = config.get(\"ensemble_options\").get('LIRM', {})\n",
    "LIRM_args = {\n",
    "            \"use_icp_initialization\": False,\n",
    "            \"verbose\": 1,\n",
    "            \"n_iterations\": 100, # 1000\n",
    "            \"seed\": 0,\n",
    "            \"lr\": 0.005, # 0.001\n",
    "            \"cuda\": False\n",
    "        }\n",
    "LIRM_args.update(LIRM_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30bd9ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_for_synthetic_experiment(n_example, dim_inv, dim_spu, n_exp_train, n_exp_test, n_env, save_dir):\n",
    "    # training data\n",
    "    generator_example(n_example, dim_inv, dim_spu, n_exp_train, n_env ,save_dir, False)\n",
    "    outfile_train = os.path.join(save_dir,\"data_fb_example_%s_dim_inv_%s_dim_spu_%s_n_exp_%s_n_env_%s_test_%s.pickle\" %(n_example, dim_inv, dim_spu, n_exp_train, n_env, False))\n",
    "\n",
    "    # test data\n",
    "    generator_example(n_example, dim_inv, dim_spu, n_exp_test, n_env ,save_dir, True)\n",
    "    outfile_test = os.path.join(save_dir,\"data_fb_example_%s_dim_inv_%s_dim_spu_%s_n_exp_%s_n_env_%s_test_%s.pickle\" %(n_example, dim_inv, dim_spu, n_exp_test, n_env, True))\n",
    "    \n",
    "    return outfile_train, outfile_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92aad2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "n_example: 1 output_data_regime: real-valued \n",
      "\n",
      "\n",
      "Environments variables: {'E0': 0.1, 'E1': 1.5, 'E2': 2}\n",
      "Generated Synthetic Data according to the Facebook setup Example: 1\n",
      "     df with  4  columns\n",
      "Environments variables: {'E0': 0.1, 'E1': 1.5, 'E2': 2}\n",
      "Generated Synthetic Data according to the Facebook setup Example: 1\n",
      "     df with  4  columns\n",
      "Running a per sample experiment\n",
      "Using synthetic dataset train/test split\n",
      "Loaded  3  train environments\n",
      "Env  0  has  2  samples\n",
      "X shape  (2, 4)  y shape  (2, 1)\n",
      "Env  1  has  2  samples\n",
      "X shape  (2, 4)  y shape  (2, 1)\n",
      "Env  2  has  2  samples\n",
      "X shape  (2, 4)  y shape  (2, 1)\n",
      "Loaded test set, X shape: (6, 4)  y shape:  (6, 1)\n",
      "Start IRM training procedure with real-valued target\n",
      "iteration: 0 error: 104.38973999023438\n",
      "IRM (reg=0.000) has 12.035 validation error.\n",
      "\tnew best model:\n",
      "\terror: 12.03513240814209\n",
      "\treg: 0\n",
      "\tphi.trace: tensor(3.9738, grad_fn=<TraceBackward>)\n",
      "iteration: 0 error: 104.38973999023438\n",
      "IRM (reg=0.000) has 12.035 validation error.\n",
      "\tnew best model:\n",
      "\terror: 12.035101890563965\n",
      "\treg: 1e-05\n",
      "\tphi.trace: tensor(3.9738, grad_fn=<TraceBackward>)\n",
      "iteration: 0 error: 104.38973999023438\n",
      "IRM (reg=0.000) has 12.035 validation error.\n",
      "\tnew best model:\n",
      "\terror: 12.03486156463623\n",
      "\treg: 0.0001\n",
      "\tphi.trace: tensor(3.9738, grad_fn=<TraceBackward>)\n",
      "iteration: 0 error: 104.38973999023438\n",
      "IRM (reg=0.001) has 12.032 validation error.\n",
      "\tnew best model:\n",
      "\terror: 12.032475471496582\n",
      "\treg: 0.001\n",
      "\tphi.trace: tensor(3.9736, grad_fn=<TraceBackward>)\n",
      "iteration: 0 error: 104.38973999023438\n",
      "IRM (reg=0.010) has 12.008 validation error.\n",
      "\tnew best model:\n",
      "\terror: 12.00844669342041\n",
      "\treg: 0.01\n",
      "\tphi.trace: tensor(3.9718, grad_fn=<TraceBackward>)\n",
      "iteration: 0 error: 104.38973999023438\n",
      "IRM (reg=0.100) has 11.747 validation error.\n",
      "\tnew best model:\n",
      "\terror: 11.747085571289062\n",
      "\treg: 0.1\n",
      "\tphi.trace: tensor(3.9510, grad_fn=<TraceBackward>)\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for n_example in [1]:#,2,3,4,5]:\n",
    "    output_data_regime = config[\"data_options\"][\"output_data_regime\"][n_example-1]\n",
    "    print(\"\\n\\nn_example:\", n_example, \"output_data_regime:\", output_data_regime, \"\\n\\n\")\n",
    "    \n",
    "    outfile_train, outfile_test = get_dataset_for_synthetic_experiment(n_example, dim_inv, dim_spu, n_exp_train, n_exp_test, n_env, save_dir)\n",
    "    df_train = pd.read_pickle(outfile_train)\n",
    "    df_test = pd.read_pickle(outfile_test)\n",
    "\n",
    "    config[\"data_options\"][\"dataset_fp_train\"] = outfile_train\n",
    "    config[\"data_options\"][\"dataset_fp_test\"] = outfile_test\n",
    "    config[\"data_options\"][\"predictors\"] = list(df_train.columns[0:dim_inv+dim_spu])\n",
    "    environment_datasets, val_dataset, test_dataset = get_datasets_for_experiment(config)\n",
    "\n",
    "    LIRM_args[\"target\"] = config[\"data_options\"][\"targets\"]\n",
    "    LIRM_args[\"output_data_regime\"] = output_data_regime\n",
    "    LIRM_args[\"columns\"] = test_dataset.predictor_columns\n",
    "\n",
    "    mouse_base_data = MouseInitialiser(environment_datasets, val_dataset, test_dataset, LIRM_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f041f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = mouse_base_data.mouse_phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "172ea7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start IRM training procedure with real-valued target\n",
      "iteration: 0 error: 17.620630264282227\n",
      "IRM (reg=0.000) has 5.344 validation error.\n",
      "\tnew best model:\n",
      "\terror: 5.3438720703125\n",
      "\treg: 0\n",
      "\tphi.trace: tensor(3.1656, grad_fn=<TraceBackward>)\n",
      "iteration: 0 error: 8.01580810546875\n",
      "IRM (reg=0.000) has 5.176 validation error.\n",
      "\tnew best model:\n",
      "\terror: 5.175507068634033\n",
      "\treg: 1e-05\n",
      "\tphi.trace: tensor(2.9480, grad_fn=<TraceBackward>)\n",
      "iteration: 0 error: 7.763260841369629\n",
      "IRM (reg=0.000) has 5.074 validation error.\n",
      "\tnew best model:\n",
      "\terror: 5.073523044586182\n",
      "\treg: 0.0001\n",
      "\tphi.trace: tensor(2.9337, grad_fn=<TraceBackward>)\n",
      "iteration: 0 error: 7.610284805297852\n",
      "IRM (reg=0.001) has 5.004 validation error.\n",
      "\tnew best model:\n",
      "\terror: 5.004339694976807\n",
      "\treg: 0.001\n",
      "\tphi.trace: tensor(2.9294, grad_fn=<TraceBackward>)\n",
      "iteration: 0 error: 7.506511688232422\n",
      "IRM (reg=0.010) has 4.594 validation error.\n",
      "\tnew best model:\n",
      "\terror: 4.593980312347412\n",
      "\treg: 0.01\n",
      "\tphi.trace: tensor(2.9235, grad_fn=<TraceBackward>)\n",
      "iteration: 0 error: 6.890970230102539\n",
      "IRM (reg=0.100) has 2.926 validation error.\n",
      "\tnew best model:\n",
      "\terror: 2.9257595539093018\n",
      "\treg: 0.1\n",
      "\tphi.trace: tensor(2.8720, grad_fn=<TraceBackward>)\n"
     ]
    }
   ],
   "source": [
    "ass = MouseInitialisedLinearInvariantRiskMinimization(environment_datasets, val_dataset, test_dataset, LIRM_args, initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e55229a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2d192a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3495ab15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lirm.w\n",
    "# I think the test logits are the things you need to mouse-initialise here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3db11164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7885, -0.2382, -0.2136, -0.2192, -0.1973],\n",
       "        [ 0.0844,  0.8118, -0.0023,  0.0131,  0.1613],\n",
       "        [-0.2093, -0.2198,  0.7903, -0.2175, -0.1949],\n",
       "        [-0.2116, -0.2398, -0.2137,  0.7812, -0.1965],\n",
       "        [-0.1837, -0.1961, -0.1864, -0.1901,  0.7792]],\n",
       "       grad_fn=<CloneBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ed9e7e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['test_logits', 'test_acc', 'test_nll', 'test_probs', 'test_labels', 'feature_coeffients', 'to_bucket'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('acc/r2:', tensor(0.2576))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(results.get(n_example).keys())\n",
    "\"acc/r2:\", results.get(n_example).get(\"test_acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "448e88e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Causal_2', 28.2161705493927),\n",
       " ('Causal_1', 26.71197199821472),\n",
       " ('Causal_0', 26.41683316230774),\n",
       " ('Causal_3', 21.73872461915016),\n",
       " ('Non_causal_7', 2.7639010846614838),\n",
       " ('Non_causal_5', 2.7266255617141724),\n",
       " ('Non_causal_2', 2.3941598534584045),\n",
       " ('Non_causal_8', 2.0637218952178955),\n",
       " ('Non_causal_6', 1.5529405996203423),\n",
       " ('Non_causal_4', 1.2595409452915192),\n",
       " ('Non_causal_3', 1.1885599195957184),\n",
       " ('Non_causal_9', 0.9855049755424261),\n",
       " ('Non_causal_1', 0.6325856596231461),\n",
       " ('Non_causal_0', 0.30464520677924156)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = results.get(n_example).get(\"to_bucket\")\n",
    "\n",
    "if output_data_regime == \"multi-class\":\n",
    "    r = sorted(zip(result.get(\"features\"), np.abs(result.get(\"coefficients\")).sum(axis=1)), key=lambda x: x[1], reverse=True)\n",
    "else:\n",
    "    r = sorted(zip(result.get(\"features\"), result.get(\"coefficients\")), key=lambda x: abs(x[1]), reverse=True)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f33d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu100.m73",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu100:m73"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

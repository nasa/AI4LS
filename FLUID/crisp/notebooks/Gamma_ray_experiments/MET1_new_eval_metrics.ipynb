{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ee390f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 100% human data as the benchmark for all these studies!\n",
    "try:\n",
    "    import rbo\n",
    "except:\n",
    "    ! pip install rbo\n",
    "    import rbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d58f9825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/crisp'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "if os.getcwd() != '/home/jupyter/crisp':\n",
    "    os.chdir(\"..\")\n",
    "from utils.gcp_helpers import get_dataframe_from_bucket\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "614a6aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09bb1c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/GSE1_only_file/results_for_bucket.json') as json_file:\n",
    "    base = json.load(json_file)\n",
    "with open('results/one_norm_file/results_for_bucket.json') as json_file:\n",
    "    comp1 = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb65086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_comparisons:\n",
    "    def __init__(self, base, comparison, model_idx):\n",
    "        self.base_frame_untrimmed = get_rank_frame(base, 0)\n",
    "        self.comparison_frame_untrimmed  = get_rank_frame(comparison,0)\n",
    "        self.base_frame, self.comparison_frame = trim_frames(self.base_frame_untrimmed,self.comparison_frame_untrimmed)\n",
    "        self.base_rank = rank(self.base_frame)\n",
    "        self.comparison_rank = rank(self.comparison_frame)\n",
    "        self.metrics = {'top_10_overlap_percent': top_n_overlap_percent(self.base_rank,self.comparison_rank,n=10),\n",
    "                        'top_20_overlap_percent': top_n_overlap_percent(self.base_rank,self.comparison_rank,n=20),\n",
    "                        'top_50_overlap_percent': top_n_overlap_percent(self.base_rank,self.comparison_rank,n=50),\n",
    "                        'ranked_bias_overlap': ranked_bias_overlap(self.base_rank,self.comparison_rank),\n",
    "                        'kendall_tau': kendall_tau(self.base_rank,self.comparison_rank),\n",
    "                        'cosine_similarity': cosine_similarity(self.base_frame, self.comparison_frame)\n",
    "                       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "60bc1d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "ob = data_comparisons(base, comp1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c290334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'top_10_overlap_percent': 0.7,\n",
       " 'top_20_overlap_percent': 0.55,\n",
       " 'top_50_overlap_percent': 0.42,\n",
       " 'ranked_bias_overlap': 0.540794753836976,\n",
       " 'kendall_tau': KendalltauResult(correlation=-0.016288900840109522, pvalue=0.40949268826669916),\n",
       " 'cosine_similarity': 0.217939876375988}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "779418ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rank_frame(json, model_idx):\n",
    "    features = json['results'][model_idx]['features']\n",
    "    coeff = json['results'][model_idx]['coefficients']\n",
    "    df = pd.DataFrame([features,coeff]).T\n",
    "    df.columns = ['features','coefficients']\n",
    "    df['rank'] = abs(df['coefficients'])\n",
    "    df = df.sort_values(['rank'],ascending = False)\n",
    "    return df\n",
    "\n",
    "def trim_frames(df1,df2):\n",
    "    size_cap = min(len(df1),len(df2))\n",
    "    df1 = df1.iloc[:size_cap]\n",
    "    df2 = df2.iloc[:size_cap]\n",
    "    return df1, df2\n",
    "\n",
    "def rank(df):\n",
    "    return list(df['features'])\n",
    "\n",
    "def ranked_bias_overlap(base_rank, comparator_rank):\n",
    "    return rbo.RankingSimilarity(base_rank, comparator_rank).rbo()\n",
    "\n",
    "def top_n_overlap_percent(base_rank, comparator_rank, n=10):\n",
    "    return len(set(base_rank[0:50]).intersection(set(comparator_rank[0:n]))) / n\n",
    "\n",
    "from scipy.stats import kendalltau\n",
    "def kendall_tau(base_rank,comparator_rank):\n",
    "    return kendalltau(base_rank, comparator_rank)\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "def cosine_similarity(base_frame, comparator_frame):\n",
    "    return 1 - cosine(base_frame['coefficients'].astype(float).to_numpy(),\n",
    "                  comparator_frame['coefficients'].astype(float).to_numpy())\n",
    "\n",
    "# def levenstein_distance(base, comparator):\n",
    "# to be added  "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu100.m73",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu100:m73"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
